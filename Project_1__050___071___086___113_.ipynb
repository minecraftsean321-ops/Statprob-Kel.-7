{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MLAtMv3ZKRx"
      },
      "source": [
        "# **Project Statprob EDA 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghvMc6eyX3Zs"
      },
      "source": [
        "**Kelompok 7:**\n",
        "\n",
        "\n",
        "1.   Sean Arthur Tamajaya || 5027251050\n",
        "2.   Muhammad Atallah Mas'udi || 5027251071\n",
        "3.   Muhammad Razzan Azizi Djauhari || 5027251086\n",
        "4.   Muhammad Ridwan || 5027251113\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RChmqga_qx2c",
        "outputId": "bfccbae6-2a9d-48ea-a329-cc0d9c3e3813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g0CHLxgrJZX"
      },
      "outputs": [],
      "source": [
        "# import requirements library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "NBofjRMkrMFp",
        "outputId": "19e05cd0-8df0-4cad-eade-1910868f71a7"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/cybersecurity_intrusion_data.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1829382933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/cybersecurity_intrusion_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/cybersecurity_intrusion_data.csv'"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "data = pd.read_csv(\"/content/cybersecurity_intrusion_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjNmSZScrVKb"
      },
      "outputs": [],
      "source": [
        "# melihat sekilas data 5 row pertama\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T45eh52zrbO-"
      },
      "outputs": [],
      "source": [
        "# get the shape of the dataset\n",
        "baris, kolom = data.shape\n",
        "print(\"baris:\", baris)\n",
        "print(\"kolom:\", kolom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoNzwJByrkVX"
      },
      "outputs": [],
      "source": [
        "# get info of the dataset\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYG5raRbro42"
      },
      "outputs": [],
      "source": [
        "# get statistical summary\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7ZUL_4Prs3k"
      },
      "outputs": [],
      "source": [
        "# Mengekstrak variabel numerik dari URL\n",
        "\n",
        "# Panjang total URL\n",
        "data['url_length'] = data['session_id'].str.len()\n",
        "\n",
        "# Panjang domain (hostname)\n",
        "from urllib.parse import urlparse\n",
        "data['domain_length'] = data['session_id'].apply(lambda x: len(urlparse(x).netloc))\n",
        "\n",
        "# Panjang path (setelah domain)\n",
        "data['path_length'] = data['session_id'].apply(lambda x: len(urlparse(x).path))\n",
        "\n",
        "# Jumlah parameter query (?key=value&...)\n",
        "data['num_params'] = data['session_id'].apply(lambda x: urlparse(x).query.count('&') + (1 if urlparse(x).query else 0))\n",
        "\n",
        "# Jumlah titik (.)\n",
        "data['num_dots'] = data['session_id'].str.count(r'\\.')\n",
        "\n",
        "# Jumlah dash (-)\n",
        "data['num_hyphens'] = data['session_id'].str.count(r'-')\n",
        "\n",
        "# Jumlah angka (0–9)\n",
        "data['num_digits'] = data['session_id'].str.count(r'\\d')\n",
        "\n",
        "# Ada https atau tidak\n",
        "data['is_https'] = data['session_id'].apply(lambda x: 1 if urlparse(x).scheme == \"https\" else 0)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20HNjWOLr6dP"
      },
      "outputs": [],
      "source": [
        "# Mengubah type kategori ke label angka\n",
        "mapping = {\"benign\": 0, \"phishing\": 1, \"defacement\": 2, \"malware\": 3}\n",
        "data[\"attack_detected_encoded\"] = data[\"attack_detected\"].map(mapping)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbJRFdlusOUN"
      },
      "outputs": [],
      "source": [
        "# get new info of the dataset\n",
        "data.info()\n",
        "\n",
        "# get statistical summary\n",
        "data.describe().round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsPMGen3sUv-"
      },
      "outputs": [],
      "source": [
        "# checking missing values\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru-fWSeesXKh"
      },
      "outputs": [],
      "source": [
        "# total baris duplikat\n",
        "print(\"Total duplicate rows:\", data.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y2EyRAqs3rr"
      },
      "outputs": [],
      "source": [
        "# mean\n",
        "# Create a histogram\n",
        "plt.hist(data[\"network_packet_size\"], bins=30, edgecolor='black', alpha=0.5, color='blue')\n",
        "\n",
        "# Add a vertical line at the mean\n",
        "mean_value = data[\"network_packet_size\"].mean()\n",
        "plt.axvline(x=mean_value, color='red', linestyle='dashed', linewidth=1, label=f'Mean = {mean_value:.2f}')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Mean of Network Packet Size')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMkPtBv9s_SQ"
      },
      "outputs": [],
      "source": [
        "# median\n",
        "# Create a histogram\n",
        "plt.hist(data[\"network_packet_size\"], bins=30, edgecolor='black', alpha=0.5, color='blue')\n",
        "\n",
        "# Add a vertical line at the median\n",
        "median_val = data[\"network_packet_size\"].median()\n",
        "plt.axvline(x=median_val, color='red', linestyle='dashed', linewidth=1, label=f'Median = {median_val:.2f}')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Median of Network Packet Size')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0y2eJjRtQhS"
      },
      "outputs": [],
      "source": [
        "# modus\n",
        "# Create a histogram\n",
        "plt.hist(data[\"network_packet_size\"], bins=30, edgecolor='black', alpha=0.5, color='blue')\n",
        "\n",
        "# Add vertical lines at the modes\n",
        "modes_val = data[\"network_packet_size\"].mode()\n",
        "for i in range(len(modes_val)):\n",
        "    plt.axvline(x=modes_val[i], color='red', linestyle='dashed', linewidth=1, label=f'Modus = {modes_val[i]:.2f}')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Modes of Network Packet Size')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hiaw9DjytTjg"
      },
      "source": [
        "# **Analisis Missing Values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzEzSk5ktdrb"
      },
      "outputs": [],
      "source": [
        "# Boxplot for outlier detection\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x=data[\"network_packet_size\"])\n",
        "plt.title(\"Boxplot Outlier Detection for Network Packet Size\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PxFQauDtj_p"
      },
      "outputs": [],
      "source": [
        "# visualize range\n",
        "# Create a histogram\n",
        "plt.hist(data[\"network_packet_size\"], bins=30, edgecolor='black', alpha=0.5, color='green')\n",
        "\n",
        "# Add vertical lines for min and max\n",
        "plt.axvline(x=min(data[\"network_packet_size\"]), color='blue', linestyle='dashed', linewidth=1, label=f'Min Data: {min(data[\"network_packet_size\"]):.2f}')\n",
        "plt.axvline(x=max(data[\"network_packet_size\"]), color='blue', linestyle='dashed', linewidth=1, label=f'Max Data: {max(data[\"network_packet_size\"]):.2f}')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Range of Network Packet Size')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQESmpmutmuv"
      },
      "outputs": [],
      "source": [
        "# Outlier Mean and Std Method\n",
        "mean = data[\"network_packet_size\"].mean()\n",
        "std = data[\"network_packet_size\"].std()\n",
        "\n",
        "upper_limit = mean + 2*std\n",
        "lower_limit = mean - 2*std\n",
        "\n",
        "print(f\"Mean: {mean:.2f}, Std: {std:.2f}\")\n",
        "print(f\"Upper limit: {upper_limit:.2f}, Lower limit: {lower_limit:.2f}\")\n",
        "\n",
        "outliers = data[(data[\"network_packet_size\"] > upper_limit) | (data[\"network_packet_size\"] < lower_limit)]\n",
        "\n",
        "print(\"\\nNormal:\")\n",
        "print(len(data) - len(outliers))\n",
        "\n",
        "print(\"\\nOutliers (Mean ± 2*Std):\")\n",
        "print(len(outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwreHz4atp_s"
      },
      "outputs": [],
      "source": [
        "# Create a histogram\n",
        "plt.hist(data[\"network_packet_size\"], bins=30, edgecolor='black', alpha=0.5, color='green')\n",
        "\n",
        "# Add vertical lines for mean and std deviation limits\n",
        "mean = data[\"network_packet_size\"].mean()\n",
        "std = data[\"network_packet_size\"].std()\n",
        "upper_limit = mean + 2*std\n",
        "lower_limit = mean - 2*std\n",
        "\n",
        "\n",
        "plt.axvline(x=mean, color='red', linestyle='dashed', linewidth=1, label=f'Mean = {mean:.2f}')\n",
        "plt.axvline(x=lower_limit, color='blue', linestyle='dashed', linewidth=1, label=f'Lower Limit: {lower_limit:.2f}')\n",
        "plt.axvline(x=upper_limit, color='blue', linestyle='dashed', linewidth=1, label=f'Upper Limit: {upper_limit:.2f}')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title(f'Distribution with Std Deviation Limits for Network Packet Size')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eesWXhutsuM"
      },
      "outputs": [],
      "source": [
        "# Outlier IQR Method\n",
        "Q1 = data[\"network_packet_size\"].quantile(0.25)\n",
        "Q2 = data[\"network_packet_size\"].quantile(0.5)\n",
        "Q3 = data[\"network_packet_size\"].quantile(0.75)\n",
        "print(\"Q1:\", Q1)\n",
        "print(\"Q3:\", Q3)\n",
        "\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "print(\"Lower Bound:\", lower_bound)\n",
        "print(\"Upper Bound:\", upper_bound)\n",
        "\n",
        "outliers_iqr = data[(data[\"network_packet_size\"] < lower_bound) | (data[\"network_packet_size\"] > upper_bound)]\n",
        "\n",
        "print(\"\\nNormal:\")\n",
        "print(len(data) - len(outliers_iqr))\n",
        "\n",
        "print(\"\\nOutliers (IQR):\")\n",
        "print(len(outliers_iqr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-03g3ZQtvDv"
      },
      "outputs": [],
      "source": [
        "# Create a histogram\n",
        "plt.hist(data[\"network_packet_size\"], bins=30, edgecolor='black', alpha=0.5, color='green')\n",
        "\n",
        "# Add vertical lines for median and IQR bounds\n",
        "Q1 = data[\"network_packet_size\"].quantile(0.25)\n",
        "Q2 = data[\"network_packet_size\"].quantile(0.5)\n",
        "Q3 = data[\"network_packet_size\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "plt.axvline(x=Q2, color='red', linestyle='dashed', linewidth=1, label=f'Median = {Q2:.2f}')\n",
        "plt.axvline(x=lower_bound, color='blue', linestyle='dashed', linewidth=1, label=f'Lower Bound: {lower_bound:.2f}')\n",
        "plt.axvline(x=upper_bound, color='blue', linestyle='dashed', linewidth=1, label=f'Upper Bound: {upper_bound:.2f}')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title(f'Distribution with IQR Bounds for Network Packet Size')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSFIUkGst1Wa"
      },
      "source": [
        "# **Univariate Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ze_1LhRrt5cF"
      },
      "outputs": [],
      "source": [
        "# checking balance label\n",
        "data.value_counts(\"browser_type\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_5iRrMKuky3"
      },
      "outputs": [],
      "source": [
        "# visualize each label\n",
        "freq = data[\"browser_type\"].value_counts().sort_values(ascending=False)\n",
        "sns.countplot(x=\"browser_type\", data=data, order=freq.index)\n",
        "plt.title(\"Barplot Frekuensi Kategori (type attack)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmull2v9xLSk"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "# 1. Menentukan banyak data\n",
        "n = data[\"network_packet_size\"].count()\n",
        "print(\"1. n =\", n)\n",
        "\n",
        "# membuat histogram secara manual untuk kolom network_packet_size\n",
        "d_min = data[\"network_packet_size\"].min()\n",
        "d_max = data[\"network_packet_size\"].max()\n",
        "print(\"2. Dmin =\", d_min, \", Dmax =\", d_max)\n",
        "\n",
        "# 3. Menghitung rentang data\n",
        "R = d_max - d_min\n",
        "print(\"3. R =\", R)\n",
        "\n",
        "# 4. Menentukan banyak kelas\n",
        "k = math.ceil(1 + 3.3 * math.log(n, 10))\n",
        "print(\"4. Banyak kelas =\", k)\n",
        "\n",
        "# 5. Menghitung panjang interval kelas\n",
        "I = math.ceil(R / k)\n",
        "print(\"5. Panjang interval kelas =\", I)\n",
        "\n",
        "# 6. Menghitung interval kelas dan tepi kelas\n",
        "kelas = []\n",
        "interval_kelas = []\n",
        "tepi_kelas = [] # hanya ambil BAK - 0,5\n",
        "for i in range(k):\n",
        "    BAK = d_min + i * I\n",
        "    BBK = BAK + I\n",
        "    tepi = BAK - 0.5\n",
        "    kelas.append(i + 1)\n",
        "    interval_kelas.append(str(BAK) + \"-\" + str(BBK))\n",
        "    tepi_kelas.append(tepi)\n",
        "tepi_kelas.append(BBK + 0.5)\n",
        "print(\"6. Kelas =\", kelas)\n",
        "print(\"6. Interval kelas =\", interval_kelas)\n",
        "print(\"6. Tepi kelas =\", tepi_kelas)\n",
        "\n",
        "\n",
        "# 7. Menghitung frekuensi tiap kelas\n",
        "\n",
        "# Convert data into a pandas DataFrame\n",
        "df = data.copy()\n",
        "\n",
        "# Create frequency distribution using pd.cut and value_counts\n",
        "df[\"range\"] = pd.cut(df[\"network_packet_size\"], bins=tepi_kelas, labels=interval_kelas, include_lowest=True)\n",
        "frequency_table = df[\"range\"].value_counts().sort_index()\n",
        "relative_frequency = frequency_table / frequency_table.sum() * 100\n",
        "\n",
        "# Convert to DataFrame for a cleaner look\n",
        "frequency_distribution = pd.DataFrame(\n",
        "    {\n",
        "        \"Kelas\": kelas,\n",
        "        \"Range\": frequency_table.index,\n",
        "        \"Frequency\": frequency_table.values,\n",
        "        \"Relative Frequency (%)\": relative_frequency,\n",
        "    }\n",
        ")\n",
        "frequency_distribution.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display the frequency distribution table\n",
        "print(\"\\nTable of Frequency Distribution\")\n",
        "print(frequency_distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHmxf5PZylEy"
      },
      "outputs": [],
      "source": [
        "# Plotting the histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(\n",
        "    frequency_distribution[\"Range\"],\n",
        "    frequency_distribution[\"Frequency\"],\n",
        "    width=1,\n",
        "    edgecolor=\"black\",\n",
        "    color=\"skyblue\",\n",
        ")\n",
        "plt.title(\"Histogram of Frequency Distribution\")\n",
        "plt.xlabel(\"Range\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis=\"y\")\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z9tXge28TOc"
      },
      "source": [
        "# **Bivariate Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQqDg-X48Pr7"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='network_packet_size', y='session_duration',\n",
        "                hue= 'browser_type', data=data, )\n",
        "\n",
        "# Placing Legend outside the Figure\n",
        "plt.legend(bbox_to_anchor=(1, 1), loc=2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDGswPsC-IgK"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='network_packet_size', y='ip_reputation_score',\n",
        "                hue='browser_type', data=data, )\n",
        "\n",
        "# Placing Legend outside the Figure\n",
        "plt.legend(bbox_to_anchor=(1, 1), loc=2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYgXJvKkBBJN"
      },
      "outputs": [],
      "source": [
        "# visualize using Histogram to see the distribution of data for each columns\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10,10))\n",
        "\n",
        "axes[0,0].set_title(\"URL Length\")\n",
        "axes[0,0].hist(data_clean['url_length'], bins=10)\n",
        "\n",
        "axes[0,1].set_title(\"Domain Length\")\n",
        "axes[0,1].hist(data_clean['domain_length'], bins=10);\n",
        "\n",
        "axes[1,0].set_title(\"Path Length\")\n",
        "axes[1,0].hist(data_clean['path_length'], bins=10);\n",
        "\n",
        "axes[1,1].set_title(\"Num Params\")\n",
        "axes[1,1].hist(data_clean['num_params'], bins=10);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcn3yq17BMlu"
      },
      "outputs": [],
      "source": [
        "# Histogram with Histplot\n",
        "plot = sns.FacetGrid(data, hue=\"browser_type\", height=4)\n",
        "plot.map(sns.histplot, \"url_length\", kde=True, bins=20, alpha=0.5).add_legend()\n",
        "\n",
        "plot = sns.FacetGrid(data, hue=\"browser_type\", height=4)\n",
        "plot.map(sns.histplot, \"domain_length\", kde=True, bins=20, alpha=0.5).add_legend()\n",
        "\n",
        "plot = sns.FacetGrid(data, hue=\"browser_type\", height=4)\n",
        "plot.map(sns.histplot, \"path_length\", kde=True, bins=20, alpha=0.5).add_legend()\n",
        "\n",
        "plot = sns.FacetGrid(data, hue=\"browser_type\", height=4)\n",
        "plot.map(sns.histplot, \"num_params\", kde=True, bins=20, alpha=0.5).add_legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJUUJQbNBoUH"
      },
      "source": [
        "# **Multivariate Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J37bHL8Bl8E"
      },
      "outputs": [],
      "source": [
        "# Checking correlation\n",
        "# Drop non-numerical columns before calculating correlation\n",
        "data_numerical = data.drop([\"session_id\", \"protocol_type\", \"encryption_used\", \"browser_type\"], axis=1)\n",
        "correlation_matrix = data_numerical.corr(method='pearson').round(2)\n",
        "\n",
        "# Display the correlation matrix\n",
        "display(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab2a6ee6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file_path = \"/content/cybersecurity_intrusion_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "data_numerical = df.select_dtypes(include=['number'])\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(data_numerical.corr(method='pearson'),\n",
        "            annot=True,\n",
        "            annot_kws={\"size\": 10},\n",
        "            cmap='coolwarm',\n",
        "            fmt='.2f')\n",
        "plt.title('Heatmap Korelasi Fitur Numerik', fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hZ6wfH5PBU9"
      },
      "source": [
        "## **Korelasi Antar Fitur**\n",
        "•\tfailed_logins ↔ login_attempts = 0.80: Ini adalah korelasi positif terkuat dalam dataset. Hubungan ini sangat logis, karena semakin tinggi jumlah total percobaan login, semakin tinggi pula kemungkinan jumlah login yang gagal.\n",
        "Korelasi dengan Target (attack_detected)\n",
        "\n",
        "•\tattack_detected ↔ failed_logins = 0.58: Hubungan positif sedang. Ini adalah fitur yang paling prediktif; peningkatan jumlah login yang gagal secara signifikan meningkatkan kemungkinan terdeteksinya serangan.\n",
        "\n",
        "•\tattack_detected ↔ login_attempts = 0.52: Hubungan positif sedang. Mirip dengan failed_logins, lebih banyak percobaan login juga berasosiasi dengan deteksi serangan.\n",
        "\n",
        "•\tattack_detected ↔ unusual_time_access = 0.23: Hubungan positif lemah. Ada sedikit kecenderungan bahwa serangan terdeteksi saat akses terjadi di waktu yang tidak biasa.\n",
        "\n",
        "# **Korelasi Rendah**\n",
        "•\tBanyak variabel menunjukkan korelasi yang sangat lemah (nilai antara -0.1 dan 0.1) dengan attack_detected. Contohnya adalah session_duration (0.02) dan network_packet_size (-0.01). Ini menandakan bahwa panjangnya durasi sesi atau besarnya ukuran paket data tidak memiliki hubungan linear yang jelas dengan apakah sebuah sesi merupakan serangan atau bukan.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dhaYw0UK6m_"
      },
      "source": [
        "#**Kesimpulan Hasil Analisis Data Cybersecurity Intrusion:**\n",
        "\n",
        "Berdasarkan analisis eksploratori data cybersecurity intrusion ini, beberapa temuan kunci dan potensi masalah yang relevan untuk pemodelan prediktif telah teridentifikasi.\n",
        "\n",
        "Temuan Utama:\n",
        "\n",
        "Indikator Serangan Potensial: Variabel failed_logins dan login_attempts menunjukkan korelasi positif yang paling signifikan dengan variabel target attack_detected. Ini mengindikasikan bahwa frekuensi percobaan login yang gagal dan jumlah total percobaan login merupakan prediktor kuat terhadap kemungkinan terjadinya serangan.\n",
        "\n",
        "Variabel dengan Dampak Rendah Terhadap Target: Variabel seperti network_packet_size dan session_duration menunjukkan korelasi yang sangat lemah atau mendekati nol dengan attack_detected, menunjukkan bahwa kurang informatif untuk membedakan antara sesi normal dan sesi serangan.\n",
        "\n",
        "Potensi Masalah Data:\n",
        "\n",
        "Missing Values: Kolom encryption_used memiliki proporsi missing values yang substansial (sekitar 20.6%), yang memerlukan strategi penanganan sebelum digunakan dalam analisis atau pemodelan.\n",
        "Ketidakseimbangan Kelas: Distribusi kelas target attack_detected relatif seimbang (sekitar 44.7% serangan), namun perlu dipertimbangkan saat memilih metrik evaluasi model dan, jika diperlukan, menerapkan teknik penanganan ketidakseimbangan kelas.\n",
        "Kesalahan Pemrosesan: Kolom attack_detected_encoded saat ini tidak berisi nilai yang valid (hanya NaN), yang mengindikasikan kesalahan dalam proses encoding yang perlu diperbaiki.\n",
        "\n",
        "Implikasi untuk Pemodelan:\n",
        "\n",
        "Variabel failed_logins, login_attempts, dan ip_reputation_score adalah kandidat fitur utama untuk pembangunan model deteksi serangan. Diperlukan langkah-langkah pra-pemrosesan data tambahan, termasuk penanganan missing values pada encryption_used dan koreksi pada kolom attack_detected_encoded. Evaluasi model sebaiknya menggunakan metrik yang sesuai untuk klasifikasi biner, dan pertimbangan dapat diberikan untuk teknik penanganan ketidakseimbangan kelas jika performa model awal memerlukannya.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
